{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dt = datetime.now()\n",
    "print(\"Current datetime: \", curr_dt)\n",
    "timestamp = int(round(curr_dt.timestamp()))\n",
    "\n",
    "rows = []\n",
    "\n",
    "for k in range(100):\n",
    "    metrics = []\n",
    "    for index in range(1, 101):\n",
    "        metrics.append({\n",
    "            \"name\": f'A{index}',\n",
    "            \"tagIndex\": index,\n",
    "            \"tagValue\": random.random() * 10000\n",
    "        })\n",
    "\n",
    "    rows.append(json.dumps({\n",
    "        \"deviceId\":  random.randint(1000, 10000),\n",
    "        \"timestamp\": timestamp,\n",
    "        \"metrics\": metrics\n",
    "    }))\n",
    "\n",
    "with open(\"./io_test_data.json\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [\"device_id text not null\", \"data_ts timestamp with timezone not null \"]\n",
    "for k in range(1, 101):\n",
    "    tables.append(\"A%d numeric(20,3) null\" % (k))\n",
    "\n",
    "with open(\"./io_test_schema.sql\", \"w\") as f:\n",
    "    f.write(\"create table device_performance (\")\n",
    "    f.write(\"id SERIAL PRIMARY KEY,\")\n",
    "    f.write(\",\".join(tables))\n",
    "    f.write(\");\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_rows = []\n",
    "for k in range(100):\n",
    "    csv_rows.append( [random.randint(100, 10000)] + [f\"'{curr_dt}'\"] + [round((random.random() * 1000), 3) for k in range(1, 101)])\n",
    "\n",
    "cols = [\"device_id, data_ts\"]\n",
    "for k in range(1, 101):\n",
    "    cols.append(f\"A{k}\")\n",
    "\n",
    "cols = \",\".join(cols)\n",
    "\n",
    "batch_sql = f\"insert into device_performance ({cols}) values \\n\"\n",
    "\n",
    "with open(\"./io_test_csv.sql\", \"w\") as f:\n",
    "    tmp = [\",\".join([str(k) for k in row]) for row in csv_rows] # columns\n",
    "    sql = [f\"({col}),\" for col in tmp]\n",
    "    f.write(batch_sql + \"\\n\".join(sql) + \";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current datetime:  2024-08-16 21:44:28.544730\n"
     ]
    }
   ],
   "source": [
    "curr_dt = datetime.now()\n",
    "print(\"Current datetime: \", curr_dt)\n",
    "timestamp = int(round(curr_dt.timestamp()))\n",
    "\n",
    "rows = []\n",
    "\n",
    "for k in range(100):\n",
    "    metrics = {}\n",
    "    for index in range(1, 101):\n",
    "        metrics[f'A{index}'] = random.random() * 10000\n",
    "\n",
    "    rows.append(json.dumps({\n",
    "        \"deviceId\":  random.randint(1000, 10000),\n",
    "        \"ts\": timestamp,\n",
    "        \"metrics\": metrics\n",
    "    }))\n",
    "\n",
    "with open(\"./io_test_data_compact.json\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(rows))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
